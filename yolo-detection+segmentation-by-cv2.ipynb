{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6021726,"sourceType":"datasetVersion","datasetId":3446188},{"sourceId":8712465,"sourceType":"datasetVersion","datasetId":5225353}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport shutil\nimport cv2\n\n\ndef clean_coco_json(json_path, images_dir, output_path):\n    with open(json_path, 'r') as f:\n        data = json.load(f)\n\n    existing_images = set(os.listdir(images_dir))\n\n    clean_images = []\n    clean_annotations = []\n\n    existing_image_ids = set()\n\n    for image in data['images']:\n        if image['file_name'] in existing_images:\n            clean_images.append(image)\n            existing_image_ids.add(image['id'])\n\n    for annotation in data['annotations']:\n        if annotation['image_id'] in existing_image_ids:\n            clean_annotations.append(annotation)\n\n    data['images'] = clean_images\n    data['annotations'] = clean_annotations\n\n    with open(output_path, 'w') as f:\n        json.dump(data, f, indent=4)\n\n    print(f\"懈械薪懈泄 JSON 邪泄谢 蟹斜械械卸械薪芯 蟹邪 邪写械芯: {output_path}\")\n\n\nclean_coco_json(\n    json_path='/kaggle/input/livecell/livecell_coco_test.json',\n    images_dir='/kaggle/input/livecell/images/images/livecell_test_images',\n    output_path='./livecell_coco_test.json'\n)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-06-26T09:08:51.392308Z","iopub.execute_input":"2024-06-26T09:08:51.392653Z","iopub.status.idle":"2024-06-26T09:10:06.542188Z","shell.execute_reply.started":"2024-06-26T09:08:51.392623Z","shell.execute_reply":"2024-06-26T09:10:06.541292Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"懈械薪懈泄 JSON 邪泄谢 蟹斜械械卸械薪芯 蟹邪 邪写械芯: ./livecell_coco_test.json\n","output_type":"stream"}]},{"cell_type":"code","source":"image_dir_train = '/kaggle/input/livecell/images/images/livecell_train_val_images'\nimage_dir_val = '/kaggle/input/livecell/images/images/livecell_train_val_images'\nimage_dir_test = '/kaggle/input/livecell/images/images/livecell_test_images'\n\ncoco_annotation_file_train = '/kaggle/input/livecell/livecell_coco_train.json'\ncoco_annotation_file_val = '/kaggle/input/livecell/livecell_coco_val.json'\ncoco_annotation_file_test = '/kaggle/working/livecell_coco_test.json'\n\noutput_label_dir_train = 'dataset/labels/train'\noutput_label_dir_val = 'dataset/labels/val'\noutput_label_dir_test = 'test_dataset/test/labels'\n\noutput_image_dir_train = 'dataset/images/train'\noutput_image_dir_val = 'dataset/images/val'\noutput_image_dir_test = 'test_dataset/test/images'\n\noutput_file = 'dataset/data.yaml'\ncategories = ['cell']\ntarget_img_size = (512, 512)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:10:06.544210Z","iopub.execute_input":"2024-06-26T09:10:06.544564Z","iopub.status.idle":"2024-06-26T09:10:06.550811Z","shell.execute_reply.started":"2024-06-26T09:10:06.544530Z","shell.execute_reply":"2024-06-26T09:10:06.549819Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nfrom pathlib import Path\n\n\ndef convert_coco_to_yolo(coco_annotation_file, output_label_dir, categories, target_img_size=None):\n    \"\"\"\n    Convert COCO annotations to YOLO format.\n\n    Parameters:\n    - coco_annotation_file: Path to COCO annotations JSON file\n    - output_label_dir: Directory to save YOLO formatted labels\n    - categories: List of categories to include\n    - target_img_size: Tuple (width, height) to resize the images, default is None (no resize)\n    \"\"\"\n\n    with open(coco_annotation_file) as f:\n        coco_data = json.load(f)\n\n    category_map = {cat['id']: i for i, cat in enumerate(coco_data['categories']) if cat['name'] in categories}\n    os.makedirs(output_label_dir, exist_ok=True)\n\n    for img in coco_data['images']:\n        img_id = img['id']\n        img_filename = img['file_name']\n        img_width, img_height = img['width'], img['height']\n\n        if target_img_size:\n            target_width, target_height = target_img_size\n            width_scale = target_width / img_width\n            height_scale = target_height / img_height\n        else:\n            width_scale = height_scale = 1\n\n        label_output_path = os.path.join(output_label_dir, Path(img_filename).stem + '.txt')\n        with open(label_output_path, 'w') as label_file:\n            for ann in coco_data['annotations']:\n                if ann['image_id'] == img_id and ann['category_id'] in category_map:\n                    x, y, width, height = ann['bbox']\n                    x_center = (x + width / 2) * width_scale / target_width\n                    y_center = (y + height / 2) * height_scale / target_height\n                    width *= width_scale / target_width\n                    height *= height_scale / target_height\n                    class_id = category_map[ann['category_id']]\n                    label_file.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n\n\nconvert_coco_to_yolo(coco_annotation_file_train, output_label_dir_train, categories, target_img_size)\nconvert_coco_to_yolo(coco_annotation_file_val, output_label_dir_val, categories, target_img_size)\nconvert_coco_to_yolo(coco_annotation_file_test, output_label_dir_test, categories, target_img_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:10:06.552186Z","iopub.execute_input":"2024-06-26T09:10:06.552489Z","iopub.status.idle":"2024-06-26T09:25:16.146709Z","shell.execute_reply.started":"2024-06-26T09:10:06.552466Z","shell.execute_reply":"2024-06-26T09:25:16.145935Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def create_test_yaml_file():\n    yaml_content = \"\"\"\npath: /kaggle/working/test_dataset/test\ntrain: images\nval: images\ntest: images\nnc: 1  # 谢泻 泻谢邪胁\nnames: ['cell']\n\"\"\"\n    yaml_path = \"/kaggle/working/test_dataset/test/dataset.yaml\"\n    with open(yaml_path, \"w\") as file:\n        file.write(yaml_content)\n    return yaml_path\n\ncreate_test_yaml_file()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:25:16.149169Z","iopub.execute_input":"2024-06-26T09:25:16.149623Z","iopub.status.idle":"2024-06-26T09:25:16.158280Z","shell.execute_reply.started":"2024-06-26T09:25:16.149576Z","shell.execute_reply":"2024-06-26T09:25:16.157417Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/test_dataset/test/dataset.yaml'"},"metadata":{}}]},{"cell_type":"code","source":"def copy_and_resize_images(image_dir, label_dir, output_image_dir, target_img_size):\n    os.makedirs(output_image_dir, exist_ok=True)\n    label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n\n    for label_file in label_files:\n        image_file = label_file.replace('.txt', '.tif')\n        src_image_path = os.path.join(image_dir, image_file)\n        dst_image_path = os.path.join(output_image_dir, image_file)\n\n        if os.path.exists(src_image_path):\n            img = cv2.imread(src_image_path)\n            resized_img = cv2.resize(img, target_img_size)\n            cv2.imwrite(dst_image_path.replace('.tif', '.jpg'), resized_img)\n\n\ncopy_and_resize_images(image_dir_train, output_label_dir_train, output_image_dir_train, target_img_size)\ncopy_and_resize_images(image_dir_val, output_label_dir_val, output_image_dir_val, target_img_size)\ncopy_and_resize_images(image_dir_test, output_label_dir_test, output_image_dir_test, target_img_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:25:16.159490Z","iopub.execute_input":"2024-06-26T09:25:16.159770Z","iopub.status.idle":"2024-06-26T09:26:46.813581Z","shell.execute_reply.started":"2024-06-26T09:25:16.159732Z","shell.execute_reply":"2024-06-26T09:26:46.812822Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nimport yaml\n\ndef create_data_yaml(train_images_dir, val_images_dir, test_images_dir, class_names, output_file):\n    data = {\n        'train': train_images_dir,\n        'val': val_images_dir,\n        'test': test_images_dir,\n        'nc': len(class_names),\n        'names': class_names\n    }\n\n    with open(output_file, 'w') as f:\n        yaml.dump(data, f, default_flow_style=False)\n\n\ncreate_data_yaml('/kaggle/working/dataset/images/train', \n                 '/kaggle/working/dataset/images/val', \n                 '/kaggle/working/dataset/images/test', categories, output_file)\n\nprint(f\"data.yaml created at {output_file}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:26:46.814588Z","iopub.execute_input":"2024-06-26T09:26:46.814854Z","iopub.status.idle":"2024-06-26T09:26:46.843933Z","shell.execute_reply.started":"2024-06-26T09:26:46.814831Z","shell.execute_reply":"2024-06-26T09:26:46.843110Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"data.yaml created at dataset/data.yaml\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import shutil\nimport os\nimport sys\nfrom colorama import Fore\nimport torch\n\n\n    \nclass SetupPipline:\n    def __init__(self, display: bool = True):\n        self.pycocotools = self.__pycocotools()\n        self.ultralytics = self.__ultralytics()\n        torch.backends.cudnn.benchmark = True\n        \n    @staticmethod\n    def __ultralytics() -> str:\n        sys.path.append(\"/kaggle/input/hubmap-tools-ultralytics-and-pycocotools/ultralytics/ultralytics\") \n        return \"successfully\"\n        \n    @staticmethod\n    def __pycocotools() -> str:\n        if not os.path.exists(\"/kaggle/working/packages\"):\n            shutil.copytree(\"/kaggle/input/hubmap-tools-ultralytics-and-pycocotools/pycocotools/pycocotools\", \"/kaggle/working/packages\")\n            os.chdir(\"/kaggle/working/packages/pycocotools-2.0.6/\")\n            os.system(\"python setup.py install\")\n            os.system(\"pip install . --no-index --find-links /kaggle/working/packages/\")\n            os.chdir(\"/kaggle/working\")\n            return \"successfully\"\n    \n    def display(self) -> None:\n        print(Fore.GREEN+f\"\\nPycocotools was installed {self.pycocotools}\")\n        print(f\"Ultralytics was installed {self.ultralytics}\"+Fore.WHITE)","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:26:46.845065Z","iopub.execute_input":"2024-06-26T09:26:46.845628Z","iopub.status.idle":"2024-06-26T09:26:49.866750Z","shell.execute_reply.started":"2024-06-26T09:26:46.845595Z","shell.execute_reply":"2024-06-26T09:26:49.865827Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"pipline = SetupPipline()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:26:49.867933Z","iopub.execute_input":"2024-06-26T09:26:49.868301Z","iopub.status.idle":"2024-06-26T09:27:37.906055Z","shell.execute_reply.started":"2024-06-26T09:26:49.868277Z","shell.execute_reply":"2024-06-26T09:27:37.905190Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` directly.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n!!\n\n        ********************************************************************************\n        Please avoid running ``setup.py`` and ``easy_install``.\n        Instead, use pypa/build, pypa/installer or other\n        standards-based tools.\n\n        See https://github.com/pypa/setuptools/issues/917 for details.\n        ********************************************************************************\n\n!!\n  self.initialize_options()\n\u001b[2;36m[06/26/24 09:26:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m listing git files failed - pretending     \u001b]8;id=98965;file:///opt/conda/lib/python3.10/site-packages/setuptools_scm/_file_finders/git.py\u001b\\\u001b[2mgit.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=996872;file:///opt/conda/lib/python3.10/site-packages/setuptools_scm/_file_finders/git.py#26\u001b\\\u001b[2m26\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m                    \u001b[0m         there aren't any                          \u001b[2m         \u001b[0m\n/opt/conda/lib/python3.10/site-packages/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /kaggle/working/packages/pycocotools-2.0.6/pycocotools/_mask.pyx\n  tree = Parsing.p_module(s, pxd, full_module_name)\n","output_type":"stream"},{"name":"stdout","text":"Compiling pycocotools/_mask.pyx because it changed.\n[1/1] Cythonizing pycocotools/_mask.pyx\n","output_type":"stream"},{"name":"stderr","text":"./common/maskApi.c: In function 'rleToBbox':\n./common/maskApi.c:151:32: warning: unused variable 'xp' [-Wunused-variable]\n  151 |     uint h, w, xs, ys, xe, ye, xp, cc; siz j, m;\n      |                                ^~\n./common/maskApi.c: In function 'rleFrPoly':\n./common/maskApi.c:197:3: warning: this 'for' clause does not guard... [-Wmisleading-indentation]\n  197 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n      |   ^~~\n./common/maskApi.c:197:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the 'for'\n  197 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n      |                                                      ^\n./common/maskApi.c:198:3: warning: this 'for' clause does not guard... [-Wmisleading-indentation]\n  198 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n      |   ^~~\n./common/maskApi.c:198:54: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the 'for'\n  198 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n      |                                                      ^\n./common/maskApi.c: In function 'rleToString':\n./common/maskApi.c:243:7: warning: this 'if' clause does not guard... [-Wmisleading-indentation]\n  243 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n      |       ^~\n./common/maskApi.c:243:27: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the 'if'\n  243 |       if(more) c |= 0x20; c+=48; s[p++]=c;\n      |                           ^\n./common/maskApi.c: In function 'rleFrString':\n./common/maskApi.c:251:3: warning: this 'while' clause does not guard... [-Wmisleading-indentation]\n  251 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n      |   ^~~~~\n./common/maskApi.c:251:22: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the 'while'\n  251 |   while( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n      |                      ^~~~\n./common/maskApi.c:259:5: warning: this 'if' clause does not guard... [-Wmisleading-indentation]\n  259 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n      |     ^~\n./common/maskApi.c:259:34: note: ...this statement, but the latter is misleadingly indented as if it were guarded by the 'if'\n  259 |     if(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n      |                                  ^~~~\npycocotools/_mask.c: In function '__pyx_pf_11pycocotools_5_mask_12iou':\npycocotools/_mask.c:10271:28: warning: comparison of integer expressions of different signedness: 'Py_ssize_t' {aka 'long int'} and 'siz' {aka 'long unsigned int'} [-Wsign-compare]\n10271 |     __pyx_t_9 = (__pyx_t_8 == __pyx_v_n);\n      |                            ^~\n","output_type":"stream"},{"name":"stdout","text":"Looking in links: /kaggle/working/packages/\nProcessing /kaggle/working/packages/pycocotools-2.0.6\n  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0.6) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0.6) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.6) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0.6) (1.16.0)\nBuilding wheels for collected packages: pycocotools\n  Building wheel for pycocotools (pyproject.toml): started\n  Building wheel for pycocotools (pyproject.toml): finished with status 'done'\n  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=109429 sha256=dedd8b2234da05f5b31ce33268238550fea68251927d8cc697b14ba9c1a22a50\n  Stored in directory: /root/.cache/pip/wheels/b7/83/32/99474500256e64154dfc568319411b6ff49e96e50f30d9474f\nSuccessfully built pycocotools\nInstalling collected packages: pycocotools\n  Attempting uninstall: pycocotools\n    Found existing installation: pycocotools 2.0.6\n    Uninstalling pycocotools-2.0.6:\n      Successfully uninstalled pycocotools-2.0.6\nSuccessfully installed pycocotools-2.0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"pipline.display()","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:27:37.907176Z","iopub.execute_input":"2024-06-26T09:27:37.907452Z","iopub.status.idle":"2024-06-26T09:27:37.912088Z","shell.execute_reply.started":"2024-06-26T09:27:37.907428Z","shell.execute_reply":"2024-06-26T09:27:37.911277Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\u001b[32m\nPycocotools was installed successfully\nUltralytics was installed successfully\u001b[37m\n","output_type":"stream"}]},{"cell_type":"code","source":"from pycocotools import _mask as coco_mask \nfrom ultralytics import YOLO","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:27:37.914907Z","iopub.execute_input":"2024-06-26T09:27:37.915668Z","iopub.status.idle":"2024-06-26T09:27:42.114494Z","shell.execute_reply.started":"2024-06-26T09:27:37.915627Z","shell.execute_reply":"2024-06-26T09:27:42.113498Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:27:42.115795Z","iopub.execute_input":"2024-06-26T09:27:42.116576Z","iopub.status.idle":"2024-06-26T09:27:42.120925Z","shell.execute_reply.started":"2024-06-26T09:27:42.116542Z","shell.execute_reply":"2024-06-26T09:27:42.120030Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport math\n\ndef main():\n    model = YOLO(\"yolov8x\")\n\n    model.train(\n        project=\"live-cell\",\n        name=\"yolov8x\",\n\n        deterministic=True,\n        seed=43,\n\n        data=\"/kaggle/working/dataset/data.yaml\",\n        save=True,\n        save_period=5,\n        pretrained=True,\n        imgsz=512,\n\n        epochs=50,\n        batch=8,\n        workers=8,\n        val=True,\n\n        lr0=0.01,\n        patience=30,\n        optimizer=\"AdamW\",\n        momentum=0.9,\n        weight_decay=0.01,\n        close_mosaic=3,\n\n        amp=True,\n        cache=True,\n    )\n    \n    return model\n\nmodel = main()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-26T09:27:42.122211Z","iopub.execute_input":"2024-06-26T09:27:42.122509Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8x.pt to yolov8x.pt...\n100%|| 131M/131M [00:01<00:00, 95.4MB/s] \nNew https://pypi.org/project/ultralytics/8.2.42 available  Update with 'pip install -U ultralytics'\nUltralytics YOLOv8.0.120  Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=/kaggle/working/dataset/data.yaml, epochs=50, patience=30, batch=8, imgsz=512, save=True, save_period=5, cache=True, device=None, workers=8, project=live-cell, name=yolov8x, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=43, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=3, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.9, weight_decay=0.01, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=live-cell/yolov8x\nDownloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n100%|| 755k/755k [00:00<00:00, 4.33MB/s]\n2024-06-26 09:27:51,186\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-06-26 09:27:52,052\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-06-26 09:27:54.429624: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-26 09:27:54.429726: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-26 09:27:54.564918: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n 22        [15, 18, 21]  1   8718931  ultralytics.nn.modules.head.Detect           [1, [320, 640, 640]]          \nModel summary: 365 layers, 68153571 parameters, 68153555 gradients\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir live-cell/yolov8x', view at http://localhost:6006/\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路路\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240626_092838-pstlctro</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/olexsandr-shyshchuk/live-cell/runs/pstlctro' target=\"_blank\">yolov8x</a></strong> to <a href='https://wandb.ai/olexsandr-shyshchuk/live-cell' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/olexsandr-shyshchuk/live-cell' target=\"_blank\">https://wandb.ai/olexsandr-shyshchuk/live-cell</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/olexsandr-shyshchuk/live-cell/runs/pstlctro' target=\"_blank\">https://wandb.ai/olexsandr-shyshchuk/live-cell/runs/pstlctro</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n100%|| 6.23M/6.23M [00:00<00:00, 22.5MB/s]\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/labels/train... 3188 images, 0 backgrounds, 0 corrupt: 100%|| 3188/3188 [00:07<00:00, 454.18it/s]\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/A172_Phase_D7_2_02d20h00m_1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BT474_Phase_A3_1_01d12h00m_4.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BT474_Phase_B3_1_04d16h00m_3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_B4_2_02d12h00m_2.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_B4_2_02d12h00m_3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_B4_2_02d12h00m_4.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_B4_2_02d20h00m_1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_B4_2_02d20h00m_3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_B4_2_02d20h00m_4.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_C4_1_01d00h00m_3.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_C4_1_02d16h00m_1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_C4_1_02d20h00m_2.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_D4_1_00d00h00m_1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_D4_1_00d04h00m_1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_D4_1_01d16h00m_2.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_D4_1_01d20h00m_4.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_D4_1_02d08h00m_2.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_D4_2_01d20h00m_3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_D4_2_02d12h00m_4.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/BV2_Phase_D4_2_02d16h00m_4.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/MCF7_Phase_F4_1_00d12h00m_1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/MCF7_Phase_F4_2_03d00h00m_4.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/MCF7_Phase_G4_2_02d20h00m_1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/SHSY5Y_Phase_B10_1_00d16h00m_1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/SHSY5Y_Phase_B10_1_00d20h00m_1.jpg: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/SHSY5Y_Phase_B10_2_03d04h00m_2.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/SHSY5Y_Phase_B10_2_03d08h00m_4.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/SHSY5Y_Phase_C10_1_01d08h00m_4.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/SHSY5Y_Phase_D10_1_00d00h00m_1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/SKOV3_Phase_H4_2_03d00h00m_3.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/train/SKOV3_Phase_H4_2_03d00h00m_4.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/labels/train.cache\n\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.3GB True): 100%|| 3188/3188 [00:02<00:00, 1222.07it/s]\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/labels/val... 569 images, 0 backgrounds, 0 corrupt: 100%|| 569/569 [00:01<00:00, 324.91it/s]\n\u001b[34m\u001b[1mval: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/val/BV2_Phase_C4_1_01d08h00m_3.jpg: 3 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/val/BV2_Phase_D4_1_02d08h00m_3.jpg: 4 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/val/BV2_Phase_D4_1_02d08h00m_4.jpg: 11 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/val/MCF7_Phase_E4_1_02d00h00m_1.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/val/MCF7_Phase_F4_1_01d00h00m_2.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mWARNING 锔 /kaggle/working/dataset/images/val/SHSY5Y_Phase_D10_2_01d20h00m_2.jpg: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/labels/val.cache\n\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.4GB True): 100%|| 569/569 [00:01<00:00, 373.02it/s]\nPlotting labels to live-cell/yolov8x/labels.jpg... \n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.01, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.01), 103 bias(decay=0.0)\nImage sizes 512 train, 512 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mlive-cell/yolov8x\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/50      4.03G      2.013     0.9921      1.213        751        512: 100%|| 399/399 [05:28<00:00,  1.21it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:26<00:00,  1.35it/s]\n                   all        569     181541      0.709      0.438      0.553      0.303\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/50      14.5G      1.881     0.8716      1.174       1387        512: 100%|| 399/399 [03:36<00:00,  1.84it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:19<00:00,  1.83it/s]\n                   all        569     181541      0.506      0.295      0.391      0.224\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/50        11G       1.81     0.8275      1.147       1363        512: 100%|| 399/399 [03:35<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:19<00:00,  1.83it/s]\n                   all        569     181541      0.781      0.456      0.592      0.336\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/50      14.8G      1.754     0.8019      1.133       2015        512: 100%|| 399/399 [03:35<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.90it/s]\n                   all        569     181541      0.701      0.414       0.54      0.301\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/50      9.38G      1.731     0.7825      1.129       1006        512: 100%|| 399/399 [03:35<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.95it/s]\n                   all        569     181541       0.81        0.5      0.632      0.384\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/50      14.3G      1.681     0.7565       1.11       2072        512: 100%|| 399/399 [03:35<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:19<00:00,  1.85it/s]\n                   all        569     181541      0.777      0.445      0.577      0.344\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/50      10.2G      1.671     0.7568      1.109       1648        512: 100%|| 399/399 [03:35<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.94it/s]\n                   all        569     181541      0.771      0.452       0.59      0.358\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/50      15.7G      1.641     0.7365      1.098       2493        512: 100%|| 399/399 [03:35<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.94it/s]\n                   all        569     181541      0.791      0.471      0.608      0.368\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/50      15.7G      1.652     0.7401      1.097       2542        512: 100%|| 399/399 [03:35<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.92it/s]\n                   all        569     181541       0.81      0.495      0.629      0.385\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/50      15.3G      1.632     0.7313      1.095       3740        512: 100%|| 399/399 [03:34<00:00,  1.86it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:19<00:00,  1.89it/s]\n                   all        569     181541      0.763      0.433      0.569      0.339\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/50      13.2G      1.615     0.7216      1.092        865        512: 100%|| 399/399 [03:35<00:00,  1.86it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.94it/s]\n                   all        569     181541      0.827       0.52      0.651       0.42\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/50        15G      1.608     0.7173      1.087       2083        512: 100%|| 399/399 [03:35<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.94it/s]\n                   all        569     181541       0.85      0.526       0.66      0.428\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/50      10.4G      1.594     0.7075      1.085       2318        512: 100%|| 399/399 [03:35<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.96it/s]\n                   all        569     181541      0.829      0.516      0.649      0.415\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/50        15G       1.57     0.6967      1.078       2044        512: 100%|| 399/399 [03:34<00:00,  1.86it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.94it/s]\n                   all        569     181541      0.845       0.52      0.656      0.424\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/50      15.3G      1.578     0.6971      1.078       1008        512: 100%|| 399/399 [03:35<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.95it/s]\n                   all        569     181541      0.849      0.524      0.658      0.426\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/50        16G      1.566     0.6948       1.08        711        512: 100%|| 399/399 [03:35<00:00,  1.86it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.95it/s]\n                   all        569     181541       0.84      0.515      0.653      0.428\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/50      10.2G      1.552     0.6861      1.072       1239        512: 100%|| 399/399 [03:34<00:00,  1.86it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.96it/s]\n                   all        569     181541      0.846      0.525      0.659      0.433\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/50      14.9G      1.559     0.6899      1.073       5201        512: 100%|| 399/399 [03:36<00:00,  1.85it/s]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|| 36/36 [00:18<00:00,  1.95it/s]\n                   all        569     181541      0.852      0.529      0.664      0.427\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/50      9.59G      1.541     0.6841      1.073       5073        512:  32%|      | 126/399 [01:08<02:34,  1.77it/s]","output_type":"stream"}]},{"cell_type":"code","source":"from ultralytics import YOLO\n\ndef evaluate_model_on_test_set():\n    best_model_path = \"/kaggle/working/live-cell/yolov8x/weights/best.pt\"\n    model = YOLO(best_model_path)\n\n    test_data_path = \"/kaggle/working/test_dataset/test/dataset.yaml\"\n    \n    results = model.val(data=test_data_path)\n    print(results.results_dict)\n\nevaluate_model_on_test_set()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\n\ndef predict_and_show_images(model, image_paths, output_dir):\n    os.makedirs(output_dir, exist_ok=True)\n    \n    for img_path in image_paths:\n        img = cv2.imread(img_path)\n        results = model(img)\n        \n        for result in results:\n            boxes = result.boxes\n            for box in boxes:\n                x1, y1, x2, y2 = map(int, box.xyxy[0])\n                \n                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n                \n        output_path = os.path.join(output_dir, os.path.basename(img_path))\n        cv2.imwrite(output_path, img)\n        \n        plt.figure(figsize=(10, 10))\n        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        plt.axis('off')\n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_and_show_images(model, ['/kaggle/working/test_dataset/test/images/SHSY5Y_Phase_A10_1_00d04h00m_3.jpg',\n                                '/kaggle/working/test_dataset/test/images/SkBr3_Phase_G3_1_03d04h00m_3.jpg'],\n                       'predict')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ultralytics import YOLO\n\ndef segment_object_within_bbox(img, bbox):\n    x1, y1, x2, y2 = bbox\n    obj = img[y1:y2, x1:x2]\n    \n    gray = cv2.cvtColor(obj, cv2.COLOR_BGR2GRAY)\n    \n    _, mask = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n    \n    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    object_contour_mask = np.zeros_like(mask)\n    cv2.drawContours(object_contour_mask, contours, -1, (255), thickness=cv2.FILLED)\n    \n    mask = cv2.bitwise_and(mask, object_contour_mask)\n    \n    color_mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n    \n    segmented = cv2.bitwise_and(obj, color_mask)\n    \n    img[y1:y2, x1:x2] = segmented\n\n\ndef predict_and_segment_images(model, image_paths, output_dir):\n    os.makedirs(output_dir, exist_ok=True)\n    \n    for img_path in image_paths:\n        img = cv2.imread(img_path)\n        results = model(img)\n        \n        for result in results:\n            boxes = result.boxes\n            \n            if not boxes:\n                print(f\"No boxes found for image {img_path}\")\n                continue\n            \n            for box in boxes:\n                x1, y1, x2, y2 = map(int, box.xyxy[0])\n                segment_object_within_bbox(img, (x1, y1, x2, y2))\n                \n                conf = box.conf[0]\n                cls = int(box.cls[0])\n                \n                '''cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n                label = f'{model.names[cls]} {conf:.2f}'\n                cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)'''\n                \n        \n        output_path = os.path.join(output_dir, os.path.basename(img_path))\n        cv2.imwrite(output_path, img)\n        \n        plt.figure(figsize=(10, 10))\n        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        plt.axis('off')\n        plt.show()\n\n\nbest_model_path = \"/kaggle/working/live-cell/yolov8x/weights/best.pt\"\nmodel = YOLO(best_model_path)\n        \npredict_and_segment_images(model, ['/kaggle/working/test_dataset/test/images/SHSY5Y_Phase_A10_1_00d04h00m_3.jpg',\n                                   '/kaggle/working/test_dataset/test/images/SkBr3_Phase_G3_1_03d04h00m_3.jpg'],\n                           'predict-seg')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}